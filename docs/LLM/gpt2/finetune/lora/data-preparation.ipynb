{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = \"dataset/data.json\"\n",
    "data_for_training: dict[Literal[\"train\", \"validation\"], str] = {\n",
    "    \"train\": \"data/train_data.json\",\n",
    "    \"validation\": \"data/val_data.json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df: pd.DataFrame, test_size=0.3, random_state: int = None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Shuffle indices\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    \n",
    "    # Split into train and test indices\n",
    "    test_size = int(len(df) * test_size)\n",
    "    test_indices = shuffled_indices[:test_size]\n",
    "    train_indices = shuffled_indices[test_size:]\n",
    "    \n",
    "    # Return train and test splits\n",
    "    return df.iloc[train_indices], df.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(data_location)\n",
    "\n",
    "# Display the number of rows before removing duplicates\n",
    "print(f\"Number of rows before deduplication: {df.shape[0]}\")\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Display the number of rows after removing duplicates\n",
    "print(f\"Number of rows after deduplication: {df.shape[0]}\")\n",
    "\n",
    "# Split the original dataset into train and validation sets (70% train, 30% validation)\n",
    "train_df, val_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define a list of action-based prefix variations\n",
    "prefix_variations = [\n",
    "    \"Extracting the job title from the given input\",\n",
    "    \"Determining the job title based on the provided description\",\n",
    "    \"Processing the input to identify the job title\",\n",
    "    \"Identifying the job title in the following context\",\n",
    "    \"Finding the job title from the information below\"\n",
    "]\n",
    "\n",
    "# Function to apply prefix variations to a DataFrame\n",
    "def apply_prefix_variations(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    augmented_rows: list[dict[Literal[\"text\"], str]] = []\n",
    "    \n",
    "    # Generate more samples by applying all prefixes to each row\n",
    "    for _, row in df.iterrows():\n",
    "        for prefix in prefix_variations:\n",
    "            # Create a new row with each prefix variation\n",
    "            new_text = f\"{prefix}\\ntext: {row['input']}\\njob title: {row['target']} <STOP>\"\n",
    "            augmented_rows.append({\"text\": new_text})\n",
    "    \n",
    "    # Return a new DataFrame with the augmented data\n",
    "    return pd.DataFrame(augmented_rows)\n",
    "\n",
    "# Apply prefix variations to both train and validation datasets\n",
    "train_augmented_df = apply_prefix_variations(train_df)\n",
    "val_augmented_df = apply_prefix_variations(val_df)\n",
    "\n",
    "print(f\"Augmented Train Dataframe: {train_augmented_df.shape[0]} rows\")\n",
    "print(f\"Augmented Validation Dataframe: {val_augmented_df.shape[0]} rows\")\n",
    "\n",
    "# Convert DataFrames to list of dictionaries for JSON format\n",
    "train_data = train_augmented_df.to_dict(orient='records')\n",
    "val_data = val_augmented_df.to_dict(orient='records')\n",
    "\n",
    "# Save the datasets to JSON files\n",
    "with open(data_for_training[\"train\"], 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "\n",
    "with open(data_for_training[\"validation\"], 'w') as f:\n",
    "    json.dump(val_data, f)\n",
    "\n",
    "print(\"Train and validation datasets created and saved successfully in JSON format\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
